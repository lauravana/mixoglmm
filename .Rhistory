obj
}
##############
build_cor <-
## builder the correlation matrix
function(eobj, ...) UseMethod("build_cor")
transf_cor <-
## returns a vector of parameters of the correlation structure to be shown in summary
function(eobj, ...) UseMethod("transf_cor")
dtcor.cor <- function(eobj, ...) {
## takes the original parameters which are to be displayed in summary
## computes the Jacobian for the transformed parameters entering the optimizer
## d tpar/d par
UseMethod("dtcor.cor")
}
#build_error_struct_fixed <-
#  ## extractor for correlation matrix
#  function(eobj, ...) UseMethod("build_error_struct_fixed")
#start_values <-
#  ## extractor for correlation matrix
#  function(eobj, ...) UseMethod("start_values")
#finalize_fun <-
#  ## finalizes the structures
#  function(eobj, ...) UseMethod("finalize_fun")
finalize <-
function(eobj, ...) UseMethod("finalize")
#get_covariate <-
#  ## initializes the structures
#  function(eobj, ...) UseMethod("get_covariate")
init_fun <-
## initializes the structures
function(eobj, ...) UseMethod("init_fun")
#####################
formula.cor_struct <-
## Accessor for the formula
function(x, ...) eval(attr(x, "formula"))
#####################
init_fun.cor_general <-
function(eobj,  y = NULL) {
J <- NCOL(y)
y_names <- colnames(y)
attr(eobj, "ynames") <-
attr(eobj, "ndim") <- J
attr(eobj, "npar") <- J * (J - 1)/2
attr(eobj, "start") <- double(J * (J - 1)/2)
attr(eobj, "par_names") <- apply(combn(J,2), 2, function(x) paste0("corr ", y_names[x[1]], y_names[x[2]]))
eobj
}
init_fun.cor_equi <-
function(eobj,  y = NULL) {
attr(eobj, "ynames") <- colnames(y)
attr(eobj, "ndim") <- NCOL(y)
attr(eobj, "npar") <- 1
attr(eobj, "start") <- double(1)
attr(eobj, "par_names") <- "corr"
eobj
}
init_fun.cor_ident <-
function(eobj,  y = NULL) {
attr(eobj, "ynames") <- colnames(y)
attr(eobj, "ndim") <- NCOL(y)
attr(eobj, "npar") <- 0
attr(eobj, "start") <- double(0)
attr(eobj, "par_names") <- NULL
eobj
}
################
build_cor.cor_general <-
function(eobj, tpar) {
## takes the transformed parameters and builds the general correlation matrix
## uses the spherical parameterization
ndim <- attr(eobj, "ndim")
angles <- pi * exp(tpar)/(1 + exp(tpar))
cosmat <- diag(ndim)
cosmat[lower.tri(cosmat)] <- cos(angles)
S1 <- matrix(0, nrow = ndim, ncol = ndim)
S1[, 1L] <- 1
S1[-1L, -1L][lower.tri(S1[-1L, -1L], diag = TRUE)] <- sin(angles)
tLmat <- sapply(seq_len(ndim),
function(j) cosmat[j, ] * cumprod(S1[j, ]))
sigma <- crossprod(tLmat)
return(sigma)
}
build_cor.cor_equi <-
function(eobj, tpar) {
## takes the transformed parameters and builds the general correlation matrix
## uses fisher z transformation
ndim <- attr(eobj, "ndim")
sigma <- diag(ndim)
sigma[lower.tri(sigma)] <- sigma[upper.tri(sigma)] <- z2r(tpar)
return(sigma)
}
z2r <- function(z) {
ifelse(z > 354, 1, (exp(2 * z) - 1)/(1 + exp(2 * z)))
}
build_cor.cor_ident <-
function(eobj, tpar) {
## takes the transformed parameters and builds the general correlation matrix
## uses fisher z transformation
ndim <- attr(eobj, "ndim")
sigma <- diag(ndim)
return(sigma)
}
################
transf_cor.cor_general <-
function(eobj, tpar) {
## takes the transformed parameters and builds the general correlation matrix
## uses the spherical parameterization
ndim <- attr(eobj, "ndim")
angles <- pi * exp(tpar)/(1 + exp(tpar))
cosmat <- diag(ndim)
cosmat[lower.tri(cosmat)] <- cos(angles)
S1 <- matrix(0, nrow = ndim, ncol = ndim)
S1[, 1L] <- 1
S1[-1L, -1L][lower.tri(S1[-1L, -1L], diag = TRUE)] <- sin(angles)
tLmat <- sapply(seq_len(ndim),
function(j) cosmat[j, ] * cumprod(S1[j, ]))
sigma <- crossprod(tLmat)
return(sigma[lower.tri(sigma)])
}
transf_cor.cor_equi <-
function(eobj, tpar) {
## takes the transformed parameters and builds the general correlation matrix
## uses fisher z transformation
return(z2r(tpar))
}
transf_cor.cor_ident <-
function(eobj, tpar) {
## takes the transformed parameters and builds the general correlation matrix
## uses fisher z transformation
}
################
finalize.cor_struct <- function(eobj, tpar) {
R <- build_cor(eobj, tpar)
colnames(R) <- rownames(R) <- attr(eobj,"ynames")
R
}
####
backtransf_spherical <- function(par, ndim){
R <- angmat <- diag(ndim)
R[lower.tri(R)] <- par
R[upper.tri(R)] <- t(R)[upper.tri(R)]
chR <- tryCatch(chol(R), error = function(e) NULL)
if (is.null(chR)) {
R <- Matrix::nearPD(R)$mat
chR <- chol(R)
}
l <- t(chR)
angmat[-1,1] <- acos(l[-1,1])
for (j in 2:(ndim - 1)){
sin(angmat[, seq_len(j-1), drop = FALSE])
sinprod <- exp(rowSums(log(sin(angmat[-seq_len(j), seq_len(j-1), drop = FALSE]))))
lsj <- pmax(-1, pmin(l[-seq_len(j), j]/sinprod, 1))
angmat[-seq_len(j), j] <- acos(lsj)
}
ang <- angmat[lower.tri(angmat)]
log(ang/(pi-ang))
}
dtcor.cor.cor_general <-
function(eobj, par) {
ndim <- attr(eobj, "ndim")
x <- numDeriv::jacobian(function(par) backtransf_spherical(par, ndim), par)
x
}
dtcor.cor.cor_equi <-
function(eobj, par) {
x <- 1/(1 + par) * 1/(1 - par)
if (length(par) == 1) x else diag(x)
}
dtcor.cor.cor_ident <-
function(eobj, par) {
diag(0)
}
## correlation structure for gaussian responses
obj$cor_structure <- init_fun(cor_structure, y = y2)
## Constraints lambda
if (!is.null(constraints.lambda) & is.list(constraints.lambda)) {
if (length(constraints.lambda) > 1) stop("Constraints.lambda must be a list of length one.")
constraints.lambda <- constraints.lambda[[1]]
}
constraints.lambda<-NULL
## Constraints lambda
if (!is.null(constraints.lambda) & is.list(constraints.lambda)) {
if (length(constraints.lambda) > 1) stop("Constraints.lambda must be a list of length one.")
constraints.lambda <- constraints.lambda[[1]]
}
library(mixoglmm)
## cor_general
formula <- (Be1 + Be2 + y1 + y2 + y3 ~ 1 + X1 + X2)
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
Be2 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian()),
data = data_toy,
constraints.beta = list("(Intercept)" =
cbind(c(1,1,1,1,1),
c(0,1,0,0,0),
c(0,0,1,0,0),
c(0,0,0,1,0),
c(0,0,0,0,1)),
X1 = cbind(c(1,1,1,1,1)),
X2 = cbind(c(1,1,1,1,1))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa"),
na.action = "na.pass")
)
summary(fit)
if (is.null(constraints.lambda)) {
constraints.lambda <- diag(NCOL(y))
#constraints.lambda[idn.col[1], 1] <- 1
#constraints.lambda <- constraints.lambda[, - idn.col[1], drop = FALSE]
}
constraints.lambda
## Identifiability check:
n_error_param_allowed <- (K * (K + 1)/2 - 1)
n_error_param_to_estimate <-
## correlation params in Omega
attr(obj$cor_structure, "npar") +
## Lammbda
NCOL(constraints.lambda) +
## Tau2
1 +
## sigmas
K2 +
## variance of K1-1 binaries
0
n_error_param_allowed
print(n_error_param_allowed)
print(n_error_param_to_estimate)
if (n_error_param_allowed < n_error_param_to_estimate)
stop(sprintf("No of allowed parameters is %i, to estimate we have %i.",
n_error_param_allowed, n_error_param_to_estimate))
obj$dims <- list(N = N, K = K, K1 = K1, K2 = K2,
Pstar =  NCOL(x_constr),
G = attr(obj$cor_structure, "npar"),
nlambda = NCOL(constraints.lambda))
idnn.row <- as.vector(sapply(idnn.col, function(i) (i-1) * N + seq_len(N)))
x2_constr <- x_constr[-idnn.row, ]
family_nn <- families[idnn.col]
## starting values - TODO
ty <- as.matrix(y)
## for binomial we need to transform
ty <- ty/Ntrials
start_values <- c(double(obj$dims$Pstar), #start_beta,#
double(1), # tau
attr(obj$cor_structure , "start"), # rho
double(K2),# sigmas
double(obj$dims$nlambda) + 1) # lambdas)
start_values
Z <- rep.int(1, N)
## non - normal data log lik
Ntrials <- Ntrials[,idnn.col, drop = FALSE]
ind_y2 <-
apply(unique(!is.na(y2)), 1, function(x)
list(ind.row = which(colSums(t(!is.na(y2)) == x) == NCOL(y2) ),
ind.col = x,
normfun = ifelse(sum(x) == 1, dnorm, dmvnorm)))
library(MASS)
ind_y2 <-
apply(unique(!is.na(y2)), 1, function(x)
list(ind.row = which(colSums(t(!is.na(y2)) == x) == NCOL(y2) ),
ind.col = x,
normfun = ifelse(sum(x) == 1, dnorm, dmvnorm)))
ind_y2 <-
apply(unique(!is.na(y2)), 1, function(x)
list(ind.row = which(colSums(t(!is.na(y2)) == x) == NCOL(y2) ),
ind.col = x,
normfun = ifelse(sum(x) == 1, dnorm, mvtnorm::dmvnorm)))
## Gauss-Hermite Quadrature
gq <- statmod::gauss.quad(control$nGHQ, kind = "hermite")
control$nGHQ=10
control = mixoglmm.control(solver = "newuoa")
## Gauss-Hermite Quadrature
gq <- statmod::gauss.quad(control$nGHQ, kind = "hermite")
## Optimize negative log likelihood
obj$res <- suppressWarnings(optimx(start_values, function(par) negloglik(par,
y1, y2, x_constr, #x2_constr,
Z, ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,#family_nn_ll,
obj$dims, gq),
method = control$solver,
hessian = FALSE,
control =  control$solver.optimx.control))
dmvnorm.log.cocas1 <-
function(x, sigmainv) {
# computes the log likelihood of a centered multivariate normal x
distval <- mahalanobis2(x, sigmainv)
logdet <- tryCatch(sum(log(1 / eigen(sigmainv, symmetric = TRUE, only.values = TRUE)$values)))
logretval <- - (ncol(x) * log(2 * pi) + logdet +  distval)/2
sum(logretval)
}
mahalanobis2 <-
function(x, sigmainv) {
# computes the (x - center)' sigmainv (x - center) where sigmainv = Sigma^-1
setNames(rowSums((x %*% sigmainv) * x), rownames(x))
}
mahalanobis.l <- function(x, center, cov, inverted = FALSE) {
x <- if (is.vector(x))
matrix(x, ncol = length(x))
else as.matrix(x)
x <- sweep(x, 2, center)
if (!inverted)
cov <- chol2inv(chol(cov))
setNames(rowSums((x %*% cov) * x), rownames(x))
}
dmvnorm.log.cocas <- function(x, mean, sigma, inverted) {
distval <- mahalanobis.l(x, center = mean, cov = sigma, inverted = inverted)
if (!inverted) {
logdet <- tryCatch(sum(log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values)))
} else {
logdet <- tryCatch(sum(log(1 / eigen(sigma, symmetric = TRUE, only.values = TRUE)$values)))
}
logretval <- - (ncol(x) * log(2 * pi) + logdet +  distval)/2
sum(logretval)
}
## links
## TODO include random effect in formula, otherwise it looks weird?
make.dmu.deta <- function(linkstr) {
## needed for the second derivative wrt to the random effects
switch(linkstr,
"logit"    = {
logit_link <- make.link("logit")
function(eta) logit_link$mu.eta(eta) * (1 - 2 * logit_link$linkinv(eta))
},
"probit"   = function(eta) -eta * pmax(dnorm(eta), .Machine$double.eps),
"cauchit"  = function(eta) -2 *  eta/(pi * (1 + eta^2)^2), #-2 * pi * eta * pmax(dcauchy(eta)^2, .Machine$double.eps),
"cloglog"  = function(eta) pmax((1 - exp(eta)) * exp(eta - exp(eta)), .Machine$double.eps),
# not implemeted "loglog"   = function(eta) pmax(exp(-exp(-eta) - eta) * expm1(-eta), .Machine$double.eps),
"identity" = function(eta) rep.int(0, length(eta)),
"log"      = function(eta) pmax(exp(eta), .Machine$double.eps),
"sqrt"     = function(eta) rep.int(2, length(eta)),
"1/mu^2"   = function(eta) 3/(4 * eta^2.5),
"inverse"  = function(eta) 2/(eta^3))
}
make_coef_names <- function(x_names = NULL, y_names, constraints) {
unlist(lapply(seq_along(constraints), function(i) {
cm <- constraints[[i]]
if (all(cm %in% c(0,1))) {
nam <- apply(cm, 2, function(x) paste0(y_names[as.logical(x)], collapse = "."))
} else {
nam <- seq_len(NCOL(cm))
}
paste(x_names[i], nam)
}))
}
update_families <- function(families) {
lapply(families, function(x) {
## first derivative of the log likeligood wrt to mu
x$loglik.mu <- switch(x$family,
"binomial" = function(y, mu, w, n) w * ((y/mu) - (n - y)/(1 - mu)),
"poisson"  = function(y, mu, w, n) w * (y/mu + (dpois(y, mu, log = TRUE) - y * log(mu))/mu))
## second derivative of the log likeligood wrt to mu
x$dloglik.dmu <- switch(x$family,
"binomial" = function(y, mu, w, n) w * (-(y/mu^2) - (n - y)/(1 - mu)^2),
"poisson"  = function(y, mu, w, n) w * (- y/mu^2))
## second derivative of mu wrt to eta
x$dmu.deta <-  make.dmu.deta(x$link)
x
})
}
transform_parameters2 <- function(tpar, dims, y2, x_constr, constraints.lambda,
offset, cor_structure,
idnn.row, idnn.col, ind.y2) {
# print(tpar)
beta   <-     tpar[seq_len(dims$Pstar)]
tau2   <- exp(tpar[dims$Pstar + 1])
gamma  <-     tpar[dims$Pstar + 1 + seq_len(dims$G)]
omega  <- exp(tpar[dims$Pstar + 1 + dims$G + seq_len(dims$K2)])
lambda <- tpar[dims$Pstar + 1 + dims$G + dims$K2 + seq_len(dims$nlambda)]
lambda <- drop(constraints.lambda %*% c(lambda))
lambda1 <- lambda[ idnn.col] # rep.int(1, dims$K1)
lambda2 <- lambda[-idnn.col] # rep.int(1, dims$K2)
R <- build_cor(cor_structure, gamma)
Omega <- tcrossprod(omega) * R
Sigma <- Omega + tau2 * tcrossprod(lambda2)
Sigmainv <- tryCatch(chol2inv(chol(Sigma)))
## Xbeta
xbeta  <- x_constr %*% beta + offset
## Xbeta non-normal responses
xbeta1 <- matrix(xbeta[ idnn.row, ], ncol = dims$K1)
## Xbeta normal responses
xbeta2 <- matrix(xbeta[-idnn.row, ], ncol = dims$K2)
## Errors of normal responses
eps <- y2 - xbeta2
eps[is.na(eps)] <- 0
## Parameters of the (normal) posterior distribution of the random effects
lambda2TSigmainv <- crossprod(lambda2, Sigmainv)
kappa2 <- tau2 - tau2^2 * drop(lambda2TSigmainv %*% lambda2)
nu     <- tau2 * drop(tcrossprod(eps, lambda2TSigmainv))
#nu <- tau2 * sapply(seq_len(dims$N), function(i) sum(eps[i, ] * lambda2TSigmainv, na.rm = T))
output <- list(lambda1 = lambda1,
lambda2 = lambda2,
Sigma = Sigma,
Sigmainv = Sigmainv,
xbeta1 = xbeta1,
xbeta2 = xbeta2,
y2errors = eps,
nu = nu, kappa2 = kappa2)
}
make_lambda_names <- function(
y_names = colnames(y),
constraints = constraints.lambda) {
paste("lambda", sapply(1:NCOL(constraints.lambda), function(i)
paste0(y_names[as.logical(constraints.lambda[,i])], collapse = ".")))
}
dttau2.tau <- function(x) if (length(x) == 1) 2/x^2 else diag(2/x^2)
dtomega.omega <- function(x) if (length(x) == 1) 1/x else diag(1/x)
## Optimize negative log likelihood
obj$res <- suppressWarnings(optimx(start_values, function(par) negloglik(par,
y1, y2, x_constr, #x2_constr,
Z, ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,#family_nn_ll,
obj$dims, gq),
method = control$solver,
hessian = FALSE,
control =  control$solver.optimx.control))
# obj$res <- nlminb(start_values, function(par) negloglik(par,
#                                                      y1, y2, x_constr, #x2_constr,
#                                                      Z, ind_y2,
#                                                      constraints.lambda,
#                                                      obj$cor_structure,
#                                                      w, Ntrials, offset,idnn.row, idnn.col,
#                                                      family_nn,#family_nn_ll,
#                                                      obj$dims, gq),
#                   control = control$solver.nlminb.control)
obj$par <- unlist(obj$res[1:length(start_values)])
obj$objective <- unlist(obj$res["value"])
if (obj$res$convcode != 0){
print(obj$res)
warning("NO/FALSE CONVERGENCE - choose a different optimizer, increase iterations or use different starting values.")
}
## Compute Hessian numerically
tparHess <- numDeriv::hessian(function(par) negloglik(par,
y1, y2, x_constr,
Z,ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,
obj$dims, gq), obj$par)
dims
obj$cor_structure
offset
offset<-0
## Optimize negative log likelihood
obj$res <- suppressWarnings(optimx(start_values, function(par) negloglik(par,
y1, y2, x_constr, #x2_constr,
Z, ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,#family_nn_ll,
obj$dims, gq),
method = control$solver,
hessian = FALSE,
control =  control$solver.optimx.control))
## Compute Hessian numerically
tparHess <- numDeriv::hessian(function(par) negloglik(par,
y1, y2, x_constr,
Z,ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,
obj$dims, gq), obj$par)
obj$par
## Optimize negative log likelihood
obj$res <- suppressWarnings(optimx(start_values, function(par) negloglik(par,
y1, y2, x_constr, #x2_constr,
Z, ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,#family_nn_ll,
obj$dims, gq),
method = control$solver,
hessian = FALSE,
control =  control$solver.optimx.control))
traceback()
tpar
tpar<-start_values
# print(tpar)
beta   <-     tpar[seq_len(dims$Pstar)]
obj$dims <- list(N = N, K = K, K1 = K1, K2 = K2,
Pstar =  NCOL(x_constr),
G = attr(obj$cor_structure, "npar"),
nlambda = NCOL(constraints.lambda))
dims <-  obj$dims
# print(tpar)
beta   <-     tpar[seq_len(dims$Pstar)]
tau2   <- exp(tpar[dims$Pstar + 1])
gamma  <-     tpar[dims$Pstar + 1 + seq_len(dims$G)]
omega  <- exp(tpar[dims$Pstar + 1 + dims$G + seq_len(dims$K2)])
lambda <- tpar[dims$Pstar + 1 + dims$G + dims$K2 + seq_len(dims$nlambda)]
lambda <- drop(constraints.lambda %*% c(lambda))
lambda1 <- lambda[ idnn.col] # rep.int(1, dims$K1)
lambda2 <- lambda[-idnn.col] # rep.int(1, dims$K2)
lambda1
lambda2
R <- build_cor(cor_structure, gamma)
gamma
cor_structure
