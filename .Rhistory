## Constraints lambda
if (!is.null(constraints.lambda) & is.list(constraints.lambda)) {
if (length(constraints.lambda) > 1) stop("Constraints.lambda must be a list of length one.")
constraints.lambda <- constraints.lambda[[1]]
}
library(mixoglmm)
## cor_general
formula <- (Be1 + Be2 + y1 + y2 + y3 ~ 1 + X1 + X2)
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
Be2 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian()),
data = data_toy,
constraints.beta = list("(Intercept)" =
cbind(c(1,1,1,1,1),
c(0,1,0,0,0),
c(0,0,1,0,0),
c(0,0,0,1,0),
c(0,0,0,0,1)),
X1 = cbind(c(1,1,1,1,1)),
X2 = cbind(c(1,1,1,1,1))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa"),
na.action = "na.pass")
)
summary(fit)
if (is.null(constraints.lambda)) {
constraints.lambda <- diag(NCOL(y))
#constraints.lambda[idn.col[1], 1] <- 1
#constraints.lambda <- constraints.lambda[, - idn.col[1], drop = FALSE]
}
constraints.lambda
## Identifiability check:
n_error_param_allowed <- (K * (K + 1)/2 - 1)
n_error_param_to_estimate <-
## correlation params in Omega
attr(obj$cor_structure, "npar") +
## Lammbda
NCOL(constraints.lambda) +
## Tau2
1 +
## sigmas
K2 +
## variance of K1-1 binaries
0
n_error_param_allowed
print(n_error_param_allowed)
print(n_error_param_to_estimate)
if (n_error_param_allowed < n_error_param_to_estimate)
stop(sprintf("No of allowed parameters is %i, to estimate we have %i.",
n_error_param_allowed, n_error_param_to_estimate))
obj$dims <- list(N = N, K = K, K1 = K1, K2 = K2,
Pstar =  NCOL(x_constr),
G = attr(obj$cor_structure, "npar"),
nlambda = NCOL(constraints.lambda))
idnn.row <- as.vector(sapply(idnn.col, function(i) (i-1) * N + seq_len(N)))
x2_constr <- x_constr[-idnn.row, ]
family_nn <- families[idnn.col]
## starting values - TODO
ty <- as.matrix(y)
## for binomial we need to transform
ty <- ty/Ntrials
start_values <- c(double(obj$dims$Pstar), #start_beta,#
double(1), # tau
attr(obj$cor_structure , "start"), # rho
double(K2),# sigmas
double(obj$dims$nlambda) + 1) # lambdas)
start_values
Z <- rep.int(1, N)
## non - normal data log lik
Ntrials <- Ntrials[,idnn.col, drop = FALSE]
ind_y2 <-
apply(unique(!is.na(y2)), 1, function(x)
list(ind.row = which(colSums(t(!is.na(y2)) == x) == NCOL(y2) ),
ind.col = x,
normfun = ifelse(sum(x) == 1, dnorm, dmvnorm)))
library(MASS)
ind_y2 <-
apply(unique(!is.na(y2)), 1, function(x)
list(ind.row = which(colSums(t(!is.na(y2)) == x) == NCOL(y2) ),
ind.col = x,
normfun = ifelse(sum(x) == 1, dnorm, dmvnorm)))
ind_y2 <-
apply(unique(!is.na(y2)), 1, function(x)
list(ind.row = which(colSums(t(!is.na(y2)) == x) == NCOL(y2) ),
ind.col = x,
normfun = ifelse(sum(x) == 1, dnorm, mvtnorm::dmvnorm)))
## Gauss-Hermite Quadrature
gq <- statmod::gauss.quad(control$nGHQ, kind = "hermite")
control$nGHQ=10
control = mixoglmm.control(solver = "newuoa")
## Gauss-Hermite Quadrature
gq <- statmod::gauss.quad(control$nGHQ, kind = "hermite")
## Optimize negative log likelihood
obj$res <- suppressWarnings(optimx(start_values, function(par) negloglik(par,
y1, y2, x_constr, #x2_constr,
Z, ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,#family_nn_ll,
obj$dims, gq),
method = control$solver,
hessian = FALSE,
control =  control$solver.optimx.control))
dmvnorm.log.cocas1 <-
function(x, sigmainv) {
# computes the log likelihood of a centered multivariate normal x
distval <- mahalanobis2(x, sigmainv)
logdet <- tryCatch(sum(log(1 / eigen(sigmainv, symmetric = TRUE, only.values = TRUE)$values)))
logretval <- - (ncol(x) * log(2 * pi) + logdet +  distval)/2
sum(logretval)
}
mahalanobis2 <-
function(x, sigmainv) {
# computes the (x - center)' sigmainv (x - center) where sigmainv = Sigma^-1
setNames(rowSums((x %*% sigmainv) * x), rownames(x))
}
mahalanobis.l <- function(x, center, cov, inverted = FALSE) {
x <- if (is.vector(x))
matrix(x, ncol = length(x))
else as.matrix(x)
x <- sweep(x, 2, center)
if (!inverted)
cov <- chol2inv(chol(cov))
setNames(rowSums((x %*% cov) * x), rownames(x))
}
dmvnorm.log.cocas <- function(x, mean, sigma, inverted) {
distval <- mahalanobis.l(x, center = mean, cov = sigma, inverted = inverted)
if (!inverted) {
logdet <- tryCatch(sum(log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values)))
} else {
logdet <- tryCatch(sum(log(1 / eigen(sigma, symmetric = TRUE, only.values = TRUE)$values)))
}
logretval <- - (ncol(x) * log(2 * pi) + logdet +  distval)/2
sum(logretval)
}
## links
## TODO include random effect in formula, otherwise it looks weird?
make.dmu.deta <- function(linkstr) {
## needed for the second derivative wrt to the random effects
switch(linkstr,
"logit"    = {
logit_link <- make.link("logit")
function(eta) logit_link$mu.eta(eta) * (1 - 2 * logit_link$linkinv(eta))
},
"probit"   = function(eta) -eta * pmax(dnorm(eta), .Machine$double.eps),
"cauchit"  = function(eta) -2 *  eta/(pi * (1 + eta^2)^2), #-2 * pi * eta * pmax(dcauchy(eta)^2, .Machine$double.eps),
"cloglog"  = function(eta) pmax((1 - exp(eta)) * exp(eta - exp(eta)), .Machine$double.eps),
# not implemeted "loglog"   = function(eta) pmax(exp(-exp(-eta) - eta) * expm1(-eta), .Machine$double.eps),
"identity" = function(eta) rep.int(0, length(eta)),
"log"      = function(eta) pmax(exp(eta), .Machine$double.eps),
"sqrt"     = function(eta) rep.int(2, length(eta)),
"1/mu^2"   = function(eta) 3/(4 * eta^2.5),
"inverse"  = function(eta) 2/(eta^3))
}
make_coef_names <- function(x_names = NULL, y_names, constraints) {
unlist(lapply(seq_along(constraints), function(i) {
cm <- constraints[[i]]
if (all(cm %in% c(0,1))) {
nam <- apply(cm, 2, function(x) paste0(y_names[as.logical(x)], collapse = "."))
} else {
nam <- seq_len(NCOL(cm))
}
paste(x_names[i], nam)
}))
}
update_families <- function(families) {
lapply(families, function(x) {
## first derivative of the log likeligood wrt to mu
x$loglik.mu <- switch(x$family,
"binomial" = function(y, mu, w, n) w * ((y/mu) - (n - y)/(1 - mu)),
"poisson"  = function(y, mu, w, n) w * (y/mu + (dpois(y, mu, log = TRUE) - y * log(mu))/mu))
## second derivative of the log likeligood wrt to mu
x$dloglik.dmu <- switch(x$family,
"binomial" = function(y, mu, w, n) w * (-(y/mu^2) - (n - y)/(1 - mu)^2),
"poisson"  = function(y, mu, w, n) w * (- y/mu^2))
## second derivative of mu wrt to eta
x$dmu.deta <-  make.dmu.deta(x$link)
x
})
}
transform_parameters2 <- function(tpar, dims, y2, x_constr, constraints.lambda,
offset, cor_structure,
idnn.row, idnn.col, ind.y2) {
# print(tpar)
beta   <-     tpar[seq_len(dims$Pstar)]
tau2   <- exp(tpar[dims$Pstar + 1])
gamma  <-     tpar[dims$Pstar + 1 + seq_len(dims$G)]
omega  <- exp(tpar[dims$Pstar + 1 + dims$G + seq_len(dims$K2)])
lambda <- tpar[dims$Pstar + 1 + dims$G + dims$K2 + seq_len(dims$nlambda)]
lambda <- drop(constraints.lambda %*% c(lambda))
lambda1 <- lambda[ idnn.col] # rep.int(1, dims$K1)
lambda2 <- lambda[-idnn.col] # rep.int(1, dims$K2)
R <- build_cor(cor_structure, gamma)
Omega <- tcrossprod(omega) * R
Sigma <- Omega + tau2 * tcrossprod(lambda2)
Sigmainv <- tryCatch(chol2inv(chol(Sigma)))
## Xbeta
xbeta  <- x_constr %*% beta + offset
## Xbeta non-normal responses
xbeta1 <- matrix(xbeta[ idnn.row, ], ncol = dims$K1)
## Xbeta normal responses
xbeta2 <- matrix(xbeta[-idnn.row, ], ncol = dims$K2)
## Errors of normal responses
eps <- y2 - xbeta2
eps[is.na(eps)] <- 0
## Parameters of the (normal) posterior distribution of the random effects
lambda2TSigmainv <- crossprod(lambda2, Sigmainv)
kappa2 <- tau2 - tau2^2 * drop(lambda2TSigmainv %*% lambda2)
nu     <- tau2 * drop(tcrossprod(eps, lambda2TSigmainv))
#nu <- tau2 * sapply(seq_len(dims$N), function(i) sum(eps[i, ] * lambda2TSigmainv, na.rm = T))
output <- list(lambda1 = lambda1,
lambda2 = lambda2,
Sigma = Sigma,
Sigmainv = Sigmainv,
xbeta1 = xbeta1,
xbeta2 = xbeta2,
y2errors = eps,
nu = nu, kappa2 = kappa2)
}
make_lambda_names <- function(
y_names = colnames(y),
constraints = constraints.lambda) {
paste("lambda", sapply(1:NCOL(constraints.lambda), function(i)
paste0(y_names[as.logical(constraints.lambda[,i])], collapse = ".")))
}
dttau2.tau <- function(x) if (length(x) == 1) 2/x^2 else diag(2/x^2)
dtomega.omega <- function(x) if (length(x) == 1) 1/x else diag(1/x)
## Optimize negative log likelihood
obj$res <- suppressWarnings(optimx(start_values, function(par) negloglik(par,
y1, y2, x_constr, #x2_constr,
Z, ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,#family_nn_ll,
obj$dims, gq),
method = control$solver,
hessian = FALSE,
control =  control$solver.optimx.control))
# obj$res <- nlminb(start_values, function(par) negloglik(par,
#                                                      y1, y2, x_constr, #x2_constr,
#                                                      Z, ind_y2,
#                                                      constraints.lambda,
#                                                      obj$cor_structure,
#                                                      w, Ntrials, offset,idnn.row, idnn.col,
#                                                      family_nn,#family_nn_ll,
#                                                      obj$dims, gq),
#                   control = control$solver.nlminb.control)
obj$par <- unlist(obj$res[1:length(start_values)])
obj$objective <- unlist(obj$res["value"])
if (obj$res$convcode != 0){
print(obj$res)
warning("NO/FALSE CONVERGENCE - choose a different optimizer, increase iterations or use different starting values.")
}
## Compute Hessian numerically
tparHess <- numDeriv::hessian(function(par) negloglik(par,
y1, y2, x_constr,
Z,ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,
obj$dims, gq), obj$par)
dims
obj$cor_structure
offset
offset<-0
## Optimize negative log likelihood
obj$res <- suppressWarnings(optimx(start_values, function(par) negloglik(par,
y1, y2, x_constr, #x2_constr,
Z, ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,#family_nn_ll,
obj$dims, gq),
method = control$solver,
hessian = FALSE,
control =  control$solver.optimx.control))
## Compute Hessian numerically
tparHess <- numDeriv::hessian(function(par) negloglik(par,
y1, y2, x_constr,
Z,ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,
obj$dims, gq), obj$par)
obj$par
## Optimize negative log likelihood
obj$res <- suppressWarnings(optimx(start_values, function(par) negloglik(par,
y1, y2, x_constr, #x2_constr,
Z, ind_y2,
constraints.lambda,
obj$cor_structure,
w, Ntrials, offset,idnn.row, idnn.col,
family_nn,#family_nn_ll,
obj$dims, gq),
method = control$solver,
hessian = FALSE,
control =  control$solver.optimx.control))
traceback()
tpar
tpar<-start_values
# print(tpar)
beta   <-     tpar[seq_len(dims$Pstar)]
obj$dims <- list(N = N, K = K, K1 = K1, K2 = K2,
Pstar =  NCOL(x_constr),
G = attr(obj$cor_structure, "npar"),
nlambda = NCOL(constraints.lambda))
dims <-  obj$dims
# print(tpar)
beta   <-     tpar[seq_len(dims$Pstar)]
tau2   <- exp(tpar[dims$Pstar + 1])
gamma  <-     tpar[dims$Pstar + 1 + seq_len(dims$G)]
omega  <- exp(tpar[dims$Pstar + 1 + dims$G + seq_len(dims$K2)])
lambda <- tpar[dims$Pstar + 1 + dims$G + dims$K2 + seq_len(dims$nlambda)]
lambda <- drop(constraints.lambda %*% c(lambda))
lambda1 <- lambda[ idnn.col] # rep.int(1, dims$K1)
lambda2 <- lambda[-idnn.col] # rep.int(1, dims$K2)
lambda1
lambda2
R <- build_cor(cor_structure, gamma)
gamma
cor_structure
m<-matrix(1:20,5)
m
r<- 1:4
sweep(m, 1, r, "-")
sweep(m, 1, r, "/")
sweep(m, 2, r, "/")
v   <- c(1, exp(tpar[dims$Pstar + seq_len(dims$nv)]))
sweep(m, 2, c(1), "/")
library(mixoglmm)
####################
# devtools::install_github("lauravana/mixoglmm", force=TRUE)
library(mixoglmm)
library(optimx)
data("data_toy", package = "mixoglmm")
data_toy$Be3 <- sample(data_toy$Be1)
## cor_general
formula <- (Be1 + Be2 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 6
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
dtomega.omega
mixoglmm::dtomega.omega
mixoglmm:::dtomega.omega
library(mixoglmm)
tol <- 1e-4
####################
# devtools::install_github("lauravana/mixoglmm", force=TRUE)
library(mixoglmm)
library(optimx)
data("data_toy", package = "mixoglmm")
data_toy$Be3 <- sample(data_toy$Be1)
## cor_general
formula <- (Be1 + Be2 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 6
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
library(mixoglmm)
biag(list(1,2, diag(10), ifelse(length(v) == 1) 1/x else diag(1/x)))
biag(list(1,2, diag(10), ifelse(TRUE, , 1)))
Matrix::bdiag(list(1,2, diag(10), ifelse(TRUE, , 1)))
Matrix::bdiag(list(1,2, diag(10), ifelse(TRUE, NULL, 1)))
library(mixoglmm)
tol <- 1e-4
####################
# devtools::install_github("lauravana/mixoglmm", force=TRUE)
library(mixoglmm)
library(optimx)
data("data_toy", package = "mixoglmm")
data_toy$Be3 <- sample(data_toy$Be1)
## cor_general
formula <- (Be1 + Be2 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 6
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
library(mixoglmm)
tol <- 1e-4
####################
# devtools::install_github("lauravana/mixoglmm", force=TRUE)
library(mixoglmm)
library(optimx)
data("data_toy", package = "mixoglmm")
data_toy$Be3 <- sample(data_toy$Be1)
## cor_general
formula <- (Be1 + Be2 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 6
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
library(mixoglmm)
tol <- 1e-4
####################
# devtools::install_github("lauravana/mixoglmm", force=TRUE)
library(mixoglmm)
library(optimx)
data("data_toy", package = "mixoglmm")
data_toy$Be3 <- sample(data_toy$Be1)
## cor_general
formula <- (Be1 + Be2 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 6
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
summary(fit)
