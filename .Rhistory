stepFactor <- 1
innerIter <- 0
ctrl$maxLineIter <- 10
u <- 0
gradient <- gprime(u)
maxGrad <- max(abs(gradient))
conv <- -1  ## Convergence flag
message <- "Iteration limit reached when updating the random effects"
logPostDens <- log_dens_u_cond_y(u, y1, tmp, family_nn, w, Ntrials, dims, gq)
## Newton-Raphson algorithm:
ctrl$innerCtrl <- "giveError"
for(i in 1:(ctrl$maxIter + 1L)) {
if(maxGrad < ctrl$gradTol) {
message <- "max|gradient| < tol, so current iterate is probably solution"
if(ctrl$trace > 0)
cat("\nOptimizer converged after", i, "iterations!", "max|grad|:",
maxGrad, message, fill = TRUE)
conv <- 0
break
}
D  <- gprimeprime(u)
step <- gradient / D
u <- u - stepFactor * step
logPostDensTry <- log_dens_u_cond_y(u, y1, tmp, family_nn, w, Ntrials, dims, gq)
lineIter <- 0
## simple line search, i.e. step halfing:
while(logPostDensTry < logPostDens) {
stepFactor <- stepFactor/2
u <- u + stepFactor * step
logPostDensTry <- log_dens_u_cond_y(u, y1, tmp, family_nn, w, Ntrials, dims, gq)
lineIter <- lineIter + 1
if(ctrl$trace > 0) cat(sprintf("iter: %i \t step factor: %0.4f\t value: %0.6f \t max|grad|:%0.3f\n",
i+innerIter, stepFactor, logPostDensTry, maxGrad))
if(lineIter > ctrl$maxLineIter){
message <- "Step factor reduced below minimum when computing the random effects."
conv <- 1
break
}
innerIter <- innerIter + 1
}
logPostDens <- logPostDensTry
gradient <- gprime(u)
maxGrad <- max(abs(gradient))
stepFactor <- min(1, 2 * stepFactor)
}
if(conv != 0)
stop(message, "\n  at iteration ", i)
return(u)
}
extract_ranef_means <- function(y1, tmp, family_nn, w, Ntrials, dims, gq) {
## gauss hermite for the posterior means
Z <- rep.int(1, dims$N)
unodes <- tcrossprod(Z, sqrt(2 * tmp$kappa2) * gq$nodes) + tmp$nu
const <- exp(rowSums(sapply(seq_len(dims$K1),  function(k) {
eta <-  tmp$xbeta1[, k] + tmp$lambda1[k] * unodes
phat   <- family_nn[[k]]$linkinv(eta)
delta <- (phat %*% gq$weights)/ sqrt(pi)
family_nn[[k]]$loglik(y1[, k], delta, w, Ntrials[, k])
}), na.rm  = TRUE))
ll <- lapply(seq_len(dims$K1),  function(k) {
eta <- tmp$xbeta1[, k] + tmp$lambda1[k] * unodes
mu  <- family_nn[[k]]$linkinv(eta)
ll  <- family_nn[[k]]$loglik(y1[, k], mu, w, Ntrials[, k])
ll[is.na(ll)] <- 0
ll
})
huj <- unodes * exp(Reduce("+", ll))
hu <- drop((huj %*% gq$weights)/ sqrt(pi))
postmeanu <- hu/const
return(postmeanu)
}
## log posterior density
log_dens_u_cond_y <- function(u, y1, tmp, family_nn, w, Ntrials, dims, gq) {
logf_mu <- sum(sapply(seq_len(dims$K1),  function(k) {
eta <- tmp$xbeta1[, k] + tmp$lambda1[k] * u
mu  <- family_nn[[k]]$linkinv(eta)
family_nn[[k]]$loglik(y = y1[, k], mu = mu, w = w,
n = Ntrials[, k])
}), na.rm = TRUE)
Z <- rep(1, dims$N)
unodes <- tcrossprod(Z, sqrt(2 * tmp$kappa2) * gq$nodes) + tmp$nu
logf_delta <- sum(sapply(seq_len(dims$K1),  function(k) {
eta <- tmp$xbeta1[, k] + tmp$lambda1[k] * unodes
phat   <- family_nn[[k]]$linkinv(eta)
delta <- (phat %*% gq$weights)/ sqrt(pi)
family_nn[[k]]$loglik(y = y1[, k], mu = delta, w = w,
n = Ntrials[, k])
}), na.rm = TRUE)
logf_mu + sum(dnorm(u, tmp$nu, sqrt(tmp$kappa2), log = TRUE)) - logf_delta
}
fit_betaconstraints <- mixoglmm(formula,
families = list(
def = binomial(link="probit"),
#rater1 = gaussian(),
#rater2 = gaussian(),
#rater3 = gaussian(),
rater4 = gaussian(),
rater5 = gaussian()),
data = data,
constraints.beta = constraints,
cor_struct_gauss = cor_equi(),
na.action = "na.pass")
####################
# devtools::install_github("lauravana/mixoglmm", force=TRUE)
library(mixoglmm)
library(optimx)
data("data_toy", package = "mixoglmm")
data_toy$Be3 <- sample(data_toy$Be1)
## cor_general
formula <- (Be1 + y1 + y2 + y3 ~ 1 + X1 + X2)
no <- 4
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
# Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian()
# y4 = gaussian(),
#  y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
## cor_general
formula <- (Be1 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 5
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
# Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
summary(fit)
set.seed(03062019)
## Number of units
N <- 500
## Number of covariates
P <- 3
## Covariates matrix
X <- cbind(Int=1, X1 = rnorm(N), X2 = rnorm(N))
## Coefficients for the binary variable
alpha <- c(0.2, -1, 0.5)
## Variance of the random effects
tau2 <- 1
##################################
## Simulation of random effects ##
##################################
u <- rnorm(N, 0, sqrt(tau2))
#############################################
## Simulation of Bernoulli random variable ##
#############################################
## Linear predictor of Bernoulli variable
eta_Be <- X %*% alpha + 2 * u
link <- "probit"
pfun <- switch(link,
"logit"  = plogis,
"probit" = pnorm,
"cauchit" = pcauchy)
Be1 <- rbinom(N, 1, pfun(eta_Be))
Be2 <- rbinom(N, 1, pfun(eta_Be))
##########################################
## Simulation of Poison random variable ##
##########################################
eta_Po <- eta_Be + 1 # only the intercept is different
Po1 <- rpois(N, lambda = exp(eta_Po))
###############################################
## Simulation of the normal random variables ##
###############################################
K2 <- 5 # Number of normal random variable
## mean of the normal random variables
beta0 <- c(- 1, 0, 1, 1, 0)
m <- t(t(eta_Be %*% (rep(1, K2))) + beta0) # only the intercept is different
## Correlation matrix
R <- matrix(c(1, 0.9, 0.6, 0.1, 0.2,
0.9, 1, 0.5,  0.2, 0.4,
0.6, 0.5,  1, 0.4, 0.3,
0.1, 0.2, 0.4, 1, 0.7,
0.2, 0.4, 0.3, 0.7, 1), ncol = K2)
R[1:3,1:3]
## Standard deviations of normal variables
omega <- c(0.5, 1, 2, 1, 2)
Omega <- tcrossprod(omega) * R
e <-  MASS::mvrnorm(N, rep.int(0, K2), Omega)
## K2 dimensional normal random variables
y2 <- m + e
data_toy <- cbind.data.frame(y1 = y2[, 1], y2 = y2[, 2], y3 = y2[, 3], y4 = y2[,4], y5 = y2[,5],
Po1 = Po1,
Be1 = Be1,
Be2 = Be2,
X1  = X[, 2],
X2  = X[, 3],
X3 = factor(sample(c("A", "B", "C"), N, replace = TRUE)))
data_toy$Be1 <- factor(data_toy$Be1, labels = c("ND", "D"))
data_toy$Be2 <- factor(data_toy$Be2, labels = c("ND", "D"))
save(data_toy, file = "data/data_toy.RData")
library(mixoglmm)
####################
# devtools::install_github("lauravana/mixoglmm", force=TRUE)
library(mixoglmm)
library(optimx)
data("data_toy", package = "mixoglmm")
data_toy$Be3 <- sample(data_toy$Be1)
## cor_general
formula <- (Be1 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 5
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
# Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
summary(fit)
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
# Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_equi(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
summary(fit)
summary(data_toy)
###############################################
## Simulation of the normal random variables ##
###############################################
K2 <- 5 # Number of normal random variable
## mean of the normal random variables
beta0 <- c(- 1, 0, 1, 1, 0)
X %*% alpha + 2 * u
m <- t(t(eta_Be %*% (rep(1, K2))) + beta0) # only the intercept is different
m
lambda2 <- 1:K2
lambda2 %*% u
crossprod(lambda2,  u)
tcrossprod(lambda2,  u)
tcrossprod(u,lambda2)
dim(tcrossprod(u,lambda2)  )
set.seed(03062019)
## Number of units
N <- 500
## Number of covariates
P <- 3
## Covariates matrix
X <- cbind(Int=1, X1 = rnorm(N), X2 = rnorm(N))
## Coefficients for the binary variable
alpha <- c(0.2, -1, 0.5)
## Variance of the random effects
tau2 <- 1
##################################
## Simulation of random effects ##
##################################
u <- rnorm(N, 0, sqrt(tau2))
#############################################
## Simulation of Bernoulli random variable ##
#############################################
## Linear predictor of Bernoulli variable
eta_Be <- X %*% alpha + 2 * u
link <- "probit"
pfun <- switch(link,
"logit"  = plogis,
"probit" = pnorm,
"cauchit" = pcauchy)
Be1 <- rbinom(N, 1, pfun(eta_Be))
Be2 <- rbinom(N, 1, pfun(eta_Be))
##########################################
## Simulation of Poison random variable ##
##########################################
eta_Po <- eta_Be + 1 # only the intercept is different
Po1 <- rpois(N, lambda = exp(eta_Po))
###############################################
## Simulation of the normal random variables ##
###############################################
K2 <- 5 # Number of normal random variable
## mean of the normal random variables
beta0 <- c(- 1, 0, 1, 1, 0)
X %*% alpha + 2 * u
lambda2 <- 1:K2
m <- t(t(X %*% alpha %*% (rep(1, K2))) + beta0) + tcrossprod(u,lambda2) # only the intercept is different
## Correlation matrix
R <- matrix(c(1, 0.9, 0.6, 0.1, 0.2,
0.9, 1, 0.5,  0.2, 0.4,
0.6, 0.5,  1, 0.4, 0.3,
0.1, 0.2, 0.4, 1, 0.7,
0.2, 0.4, 0.3, 0.7, 1), ncol = K2)
R[1:3,1:3]
## Standard deviations of normal variables
omega <- c(0.5, 1, 2, 1, 2)
Omega <- tcrossprod(omega) * R
e <-  MASS::mvrnorm(N, rep.int(0, K2), Omega)
## K2 dimensional normal random variables
y2 <- m + e
data_toy <- cbind.data.frame(y1 = y2[, 1], y2 = y2[, 2], y3 = y2[, 3], y4 = y2[,4], y5 = y2[,5],
Po1 = Po1,
Be1 = Be1,
Be2 = Be2,
X1  = X[, 2],
X2  = X[, 3],
X3 = factor(sample(c("A", "B", "C"), N, replace = TRUE)))
data_toy$Be1 <- factor(data_toy$Be1, labels = c("ND", "D"))
data_toy$Be2 <- factor(data_toy$Be2, labels = c("ND", "D"))
save(data_toy, file = "data/data_toy.RData")
library(mixoglmm)
tol <- 1e-4
####################
# devtools::install_github("lauravana/mixoglmm", force=TRUE)
library(mixoglmm)
library(optimx)
data("data_toy", package = "mixoglmm")
data_toy$Be3 <- sample(data_toy$Be1)
## cor_general
formula <- (Be1 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 5
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
# Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_equi(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
summary(fit)
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
# Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
summary(fit)
## cor_general
formula <- (Be1 + Be2 + y1 + y2 + y3 + y5 ~ 1 + X1 + X2)
no <- 6
system.time(
fit <- mixoglmm(formula,
families = list(
Be1 = binomial(link="probit"),
Be2 = binomial(link="probit"),
# Be3 = binomial(link="probit"),
y1 = gaussian(),
y2 = gaussian(),
y3 = gaussian(),
# y4 = gaussian(),
y5 = gaussian()
),
data = data_toy,
constraints.beta = list(
"(Intercept)" = cbind(rep(1,no), diag(no)[,-1]),
X1 = cbind(rep(1,no)),
X2 = cbind(rep(1,no))),
cor_struct_gauss = cor_general(~ 1),
control = mixoglmm.control(solver = "newuoa",
solver.optimx.control = list(maxit = 10000,trace = 0, kkt = FALSE)),
na.action = "na.pass")
)
summary(fit)
Be2 <- (X %*% alpha + 2 * u + rnorm(N, 0, 0.5) > 0) + 1
set.seed(03062019)
## Number of units
N <- 500
## Number of covariates
P <- 3
## Covariates matrix
X <- cbind(Int=1, X1 = rnorm(N), X2 = rnorm(N))
## Coefficients for the binary variable
alpha <- c(0.2, -1, 0.5)
## Variance of the random effects
tau2 <- 1
##################################
## Simulation of random effects ##
##################################
u <- rnorm(N, 0, sqrt(tau2))
#############################################
## Simulation of Bernoulli random variable ##
#############################################
## Linear predictor of Bernoulli variable
eta_Be <- X %*% alpha + 2 * u
link <- "probit"
pfun <- switch(link,
"logit"  = plogis,
"probit" = pnorm,
"cauchit" = pcauchy)
Be1 <- rbinom(N, 1, pfun(eta_Be))
Be2 <- (X %*% alpha + 2 * u + rnorm(N, 0, 0.5) > 0) + 1
# rbinom(N, 1, pfun(eta_Be))
##########################################
## Simulation of Poison random variable ##
##########################################
eta_Po <- eta_Be + 1 # only the intercept is different
Po1 <- rpois(N, lambda = exp(eta_Po))
###############################################
## Simulation of the normal random variables ##
###############################################
K2 <- 5 # Number of normal random variable
## mean of the normal random variables
beta0 <- c(- 1, 0, 1, 1, 0)
X %*% alpha + 2 * u
lambda2 <- 1:K2
m <- t(t(X %*% alpha %*% (rep(1, K2))) + beta0) + tcrossprod(u,lambda2) # only the intercept is different
## Correlation matrix
R <- matrix(c(1, 0.9, 0.6, 0.1, 0.2,
0.9, 1, 0.5,  0.2, 0.4,
0.6, 0.5,  1, 0.4, 0.3,
0.1, 0.2, 0.4, 1, 0.7,
0.2, 0.4, 0.3, 0.7, 1), ncol = K2)
R[1:3,1:3]
## Standard deviations of normal variables
omega <- c(0.5, 1, 2, 1, 2)
Omega <- tcrossprod(omega) * R
e <-  MASS::mvrnorm(N, rep.int(0, K2), Omega)
## K2 dimensional normal random variables
y2 <- m + e
data_toy <- cbind.data.frame(y1 = y2[, 1], y2 = y2[, 2], y3 = y2[, 3], y4 = y2[,4], y5 = y2[,5],
Po1 = Po1,
Be1 = Be1,
Be2 = Be2,
X1  = X[, 2],
X2  = X[, 3],
X3 = factor(sample(c("A", "B", "C"), N, replace = TRUE)))
data_toy$Be1 <- factor(data_toy$Be1, labels = c("ND", "D"))
data_toy$Be2 <- factor(data_toy$Be2, labels = c("ND", "D"))
save(data_toy, file = "data/data_toy.RData")
library(mixoglmm)
obj$dims <- list(N = N, K = K, K1 = K1, K2 = K2,
Pstar =  NCOL(x_constr),
nv = K1 - 1,
G = attr(obj$cor_structure, "npar"),
nlambda = NCOL(constraints.lambda))
