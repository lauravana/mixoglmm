---
title: "mixoglmm variance parametrization"
date: "2024-04-23"
output: pdf_document
---

The model is at the moment formulated as a one-factor model with loadings $\boldsymbol\lambda$. We can denote $\tilde u_{ik}=\lambda_k u_i$ for $k=1,\ldots,K$ 
where $u_i\sim N(0, \tau^2)$. 
One issue with this formulation is the fact that 
$\lambda_k$ and the variance of $u_i$ are not identifiable. We could blow up 
$u_i$ and make $\lambda_k$ smaller or the other way around. So a solution would be to either fix $\tau^2=1$ or fix e.g., the first $\lambda$ to one.

Maybe the best would be to fix $\tau^2=1$. 

# Case with one binary response

Assume we have $K$ responses, $K_1=1$ binary and $K_2=K-1$ Gaussian.
The variance of $\tilde {\boldsymbol u}_{i}=\boldsymbol\lambda u_i$ is given by:
$$
\Sigma_u=\boldsymbol\lambda \boldsymbol\lambda^\top
$$
The conditional (on the random effects) variance of the errors is
$$
\Sigma=\begin{pmatrix}
v & 0 \\
0 & \Omega
\end{pmatrix}
$$
where $v$ is not identified and is typically set to 1.

So the unconditional variance of the errors is
$$
\Sigma_e=\Sigma_u+\Sigma=\begin{pmatrix}
\lambda_1\lambda_1 + v & \lambda_1\lambda_2 & \ldots & \lambda_1\lambda_K \\
\lambda_1\lambda_2 & \lambda_2\lambda_2 + \sigma_1^2 & \\
\vdots &\vdots & \ddots \\
\lambda_1\lambda_K& \lambda_2\lambda_K + \sigma_1\sigma_{K-1}\rho_{1,K-1} &\ldots & \lambda_K\lambda_K + \sigma^2_{K-1}\\
\end{pmatrix}
$$
Only this matrix is identifiable. 
In this case we can estimate $K(K+1)/2 - 1=K^2/2 + K/2 - 1$ parameters, as 
$v$ is not identifiable. 

In our model we have:

* $K-1$ $\sigma$'s, 
* $(K-1)*(K-2)/2$ $\rho$'s, 
* no $\tau^2$ as we fixed it to one, 
* $K$ $\lambda$'s 

Total is $K-1+(K^2/2-3K/2+1)+K=K^2/2 + K/2$ so we have **one** parameter too much. So we need to fix one $\lambda_1=1$ or we can restrict the correlation structure to e.g., equi correlation.

# Case with more binary responses

Assume we have $K_1$ binary responses and $K_2$ Gaussians where $K_1+K_2=K$.

The conditional (on the random effects) variance of the errors is
$$
\Sigma=\begin{pmatrix}
v_1 & 0&0& 0 \\
0 & \ddots &0& 0 \\
0 & 0 &v_{K_1}& 0 \\
0 & 0& 0&  \Omega
\end{pmatrix}
$$
where $v_1,\ldots,v_{K_1}$ are not jointly identifiable. For now we can assume we fix them 
all to one (this can be later extended).

So the unconditional variance of the errors is
$$
\Sigma_e=\Sigma_u+\Sigma=\begin{pmatrix}
\lambda_1\lambda_1 + v_1 & \lambda_1\lambda_2 & \ldots & \lambda_1\lambda_{K_1}&\ldots&\tau^2\lambda_1\lambda_{K} \\
\vdots& \ldots & \ldots & \vdots\\
\lambda_1\lambda_{K_1} & \lambda_2\lambda_{K_1}&\ldots &  \lambda_{K_1} \lambda_{K_1}+v_{K_1} & \\
\vdots &\vdots & \ddots \\
\lambda_1\lambda_K& &&&\lambda_{K_1+1}\lambda_K + \sigma_1\sigma_{K_2}\rho_{1,K_2} &\ldots & \lambda_K\lambda_K + \sigma^2_{K_2}\\
\end{pmatrix}
$$
Only this matrix is identifiable (i.e., its lower triangle and its diagonal - up to 
one element corresponding to the binaries).
In this case we can estimate $K(K+1)/2 - 1=K^2/2 + K/2 - 1$ parameters, as 
we need to fix one $v_k$. 

In our model we have:

* $K_2$ $\sigma$'s, 
* $(K_2)*(K_2-1)/2$ $\rho$'s, 
* no $\tau^2$ (see above), 
* $K$ $\lambda$'s 
* no $v$'s as we assume we fix them all to one.

Total is $K_2+(K_2^2/2-K_2/2)+K$.
What we need is:
\begin{align}
K^2/2 + K/2 - 1 \geq K_2+(K_2^2/2-K_2/2)+K\\
K^2/2 - K/2 - 1 \geq (K_2^2/2 + K_2/2)\\
K^2 - K - 2 \geq (K_2^2+ K_2)\\
K^2 - K_2^2 \geq K + K_2 + 2 \\
(K_1 + K_2)^2 - K_2^2 \geq K_1 + K_2 + K_2 + 2 \\
K_1(2K_2 + K_1) \geq K_1 + 2K_2 + 2 \\
\underbrace{(K_1-1)}_{\geq 0}\underbrace{(2K_2 + K_1)}_{\geq 3} \geq 2 \\
\end{align}

This holds whenever $K_1 > 1$, so already for $K_1=2$ the model should be identifiable.

